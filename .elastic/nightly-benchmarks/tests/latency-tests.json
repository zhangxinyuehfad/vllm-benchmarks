[
  {
    "test_name": "latency_llama8B_tp1",
    "parameters": {
      "model": "LLAMA_3_1_8B_PATH",
      "tensor_parallel_size": 1,
      "load_format": "dummy",
      "num_iters_warmup": 5,
      "num_iters": 15
    }
  },
  {
    "test_name": "latency_qwen_2_5_tp1",
    "parameters": {
      "model": "QWEN_2_5_PATH",
      "tensor_parallel_size": 1,
      "load_format": "dummy",
      "num_iters_warmup": 5,
      "num_iters": 15,
      "max_model_len": 4096
    }
  }
]
