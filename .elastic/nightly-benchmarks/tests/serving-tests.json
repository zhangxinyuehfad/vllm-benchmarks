[
  {
    "test_name": "serving_llama8B_tp1",
    "qps_list": [
      1,
      4,
      16,
      "inf"
    ],
    "server_parameters": {
      "model": "LLAMA_3_1_8B_PATH",
      "tensor_parallel_size": 1,
      "swap_space": 16,
      "disable_log_stats": "",
      "disable_log_requests": "",
      "load_format": "dummy"
    },
    "client_parameters": {
      "model": "LLAMA_3_1_8B_PATH",
      "backend": "vllm",
      "dataset_name": "sharegpt",
      "dataset_path": "SHAREGPT_PATH",
      "num_prompts": 200
    }
  },
  {
    "test_name": "serving_qwen2_5_tp1",
    "qps_list": [
      1,
      4,
      16,
      "inf"
    ],
    "server_parameters": {
      "model": "QWEN_2_5_PATH",
      "tensor_parallel_size": 1,
      "swap_space": 16,
      "disable_log_stats": "",
      "disable_log_requests": "",
      "load_format": "dummy"
    },
    "client_parameters": {
      "model": "QWEN_2_5_PATH",
      "backend": "vllm",
      "dataset_name": "sharegpt",
      "dataset_path": "SHAREGPT_PATH",
      "num_prompts": 200,
      "max_model_len": 4096
    }
  }
]
